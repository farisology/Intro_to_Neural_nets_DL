{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import Graph, Session\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import MaxPooling3D, MaxPooling2D\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D, Deconvolution2D, Cropping2D\n",
    "from keras.layers import Input, Add, Dropout, Permute, add\n",
    "from scipy.io import loadmat\n",
    "graph = tf.Graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create to a series of CONV layers followed by Max pooling layer\n",
    "def Convblock(channel_dimension, block_no, no_of_convs) :\n",
    "    Layers = []\n",
    "    for i in range(no_of_convs) :\n",
    "        \n",
    "        Conv_name = \"conv\"+str(block_no)+\"_\"+str(i+1)\n",
    "        \n",
    "        # A constant kernel size of 3*3 is used for all convolutions\n",
    "        Layers.append(Convolution2D(channel_dimension,kernel_size = (3,3),padding = \"same\",activation = \"relu\",name = Conv_name))\n",
    "    \n",
    "    Max_pooling_name = \"pool\"+str(block_no)\n",
    "    \n",
    "    #Addding max pooling layer\n",
    "    Layers.append(MaxPooling2D(pool_size=(2, 2), strides=(2, 2),name = Max_pooling_name))\n",
    "    \n",
    "    return Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FCN_8_helper(image_size):\n",
    "    model = Sequential()\n",
    "    model.add(Permute((1,2,3),input_shape = (image_size,image_size,3)))\n",
    "    \n",
    "    for l in Convblock(64,1,2) :\n",
    "        model.add(l)\n",
    "    \n",
    "    for l in Convblock(128,2,2):\n",
    "        model.add(l)\n",
    "    \n",
    "    for l in Convblock(256,3,3):\n",
    "        model.add(l)\n",
    "    \n",
    "    for l in Convblock(512,4,3):\n",
    "        model.add(l)\n",
    "    \n",
    "    for l in Convblock(512,5,3):\n",
    "        model.add(l)\n",
    "        \n",
    "    model.add(Convolution2D(4096,kernel_size=(7,7),padding = \"same\",activation = \"relu\",name = \"fc6\"))\n",
    "      \n",
    "    #Replacing fully connnected layers of VGG Net using convolutions\n",
    "    model.add(Convolution2D(4096,kernel_size=(1,1),padding = \"same\",activation = \"relu\",name = \"fc7\"))\n",
    "    \n",
    "    # Gives the classifications scores for each of the 21 classes including background\n",
    "    model.add(Convolution2D(21,kernel_size=(1,1),padding=\"same\",activation=\"relu\",name = \"score_fr\"))\n",
    "    \n",
    "    Conv_size = model.layers[-1].output_shape[2] #16 if image size if 512\n",
    "    #print(Conv_size)\n",
    "    \n",
    "    model.add(Deconvolution2D(21,kernel_size=(4,4),strides = (2,2),padding = \"valid\",activation=None,name = \"score2\"))\n",
    "    \n",
    "    # O = ((I-K+2*P)/Stride)+1 \n",
    "    # O = Output dimesnion after convolution\n",
    "    # I = Input dimnesion\n",
    "    # K = kernel Size\n",
    "    # P = Padding\n",
    "    \n",
    "    # I = (O-1)*Stride + K \n",
    "    Deconv_size = model.layers[-1].output_shape[2] #34 if image size is 512*512\n",
    "    \n",
    "    #print(Deconv_size)\n",
    "    # 2 if image size is 512*512\n",
    "    Extra = (Deconv_size - 2*Conv_size)\n",
    "    \n",
    "    #print(Extra)\n",
    "    \n",
    "    #Cropping to get correct size\n",
    "    model.add(Cropping2D(cropping=((0,Extra),(0,Extra))))\n",
    "    \n",
    "    return model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "output = FCN_8_helper(512)\n",
    "print(len(output.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FCN_8(image_size):\n",
    "    with graph.as_default():\n",
    "        session1 = Session()\n",
    "        with session1.as_default():\n",
    "            model = Sequential()\n",
    "            fcn_8 = FCN_8_helper(image_size)\n",
    "            #Calculating conv size after the sequential block\n",
    "            #32 if image size is 512*512\n",
    "            Conv_size = fcn_8.layers[-1].output_shape[2] \n",
    "\n",
    "            #Conv to be applied on Pool4\n",
    "            skip_con1 = Convolution2D(21,kernel_size=(1,1),padding = \"same\",activation=None, name = \"score_pool4\")\n",
    "\n",
    "            #Addig skip connection which takes adds the output of Max pooling layer 4 to current layer\n",
    "            Summed = add(inputs = [skip_con1(fcn_8.layers[14].output),fcn_8.layers[-1].output])\n",
    "\n",
    "            #Upsampling output of first skip connection\n",
    "            x = Deconvolution2D(21,kernel_size=(4,4),strides = (2,2),padding = \"valid\",activation=None,name = \"score4\")(Summed)\n",
    "            x = Cropping2D(cropping=((0,2),(0,2)))(x)\n",
    "\n",
    "\n",
    "            #Conv to be applied to pool3\n",
    "            skip_con2 = Convolution2D(21,kernel_size=(1,1),padding = \"same\",activation=None, name = \"score_pool3\")\n",
    "\n",
    "            #Adding skip connection which takes output og Max pooling layer 3 to current layer\n",
    "            Summed = add(inputs = [skip_con2(fcn_8.layers[10].output),x])\n",
    "\n",
    "            #Final Up convolution which restores the original image size\n",
    "            Up = Deconvolution2D(21,kernel_size=(16,16),strides = (8,8),\n",
    "                                 padding = \"valid\",activation = None,name = \"upsample\")(Summed)\n",
    "\n",
    "            #Cropping the extra part obtained due to transpose convolution\n",
    "            final = Cropping2D(cropping = ((0,8),(0,8)))(Up)\n",
    "    \n",
    "    \n",
    "    return Model(fcn_8.input, final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    with graph.as_default():\n",
    "        session1 = Session()\n",
    "        with session1.as_default():\n",
    "            model = FCN_8(512)\n",
    "    \n",
    "    return model\n",
    "\n",
    "m = build_model()  # Your model implementation\n",
    "\n",
    "with graph.as_default():\n",
    "  # compile method actually creates the model in the graph.\n",
    "  m.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "writer = tf.summary.FileWriter(logdir='FCN8', graph=graph)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mW0402 02:53:25.166716 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0402 02:53:25.166716 123145444306944 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0402 02:53:25.167817 Reloader tf_logging.py:120] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "\u001b[0mW0402 02:53:25.167816 123145444306944 tf_logging.py:120] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "\u001b[33mW0402 02:53:25.181649 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0402 02:53:25.181648 123145444306944 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0402 02:53:25.182660 Reloader tf_logging.py:120] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "\u001b[0mW0402 02:53:25.182660 123145444306944 tf_logging.py:120] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "TensorBoard 1.12.0 at http://farisologys-MacBook-Pro.local:6006 (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
